{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import Normal\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "import struct\n",
        "import socket\n",
        "\n",
        "import matlab.engine\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_var = {\n",
        "\n",
        "    # Connection\n",
        "    'ip_address': '127.0.0.1',                  # Ip to connect\n",
        "    'port_input': 8280,                         # Port where matlab send data\n",
        "    'port_output': 8281,                        # Port where matlab receive data\n",
        "    'port_f_input': 8282,                       # DEPRECATED: Same but for feedback branch\n",
        "    'port_f_output': 8283,                      # DEPRECATED: Same but for feedback branch\n",
        "    'buffer_size': 32,                          # Number of bytes to read \n",
        "    'connection_dim_input': 4,                  # Number of data to read -> used to unpack from byte, recevied data are byte\n",
        "    'connection_dim_output': 1,                 # Number of data in output -> used to pack to byte and sedn to matlab\n",
        "    'stop_flag': [-999, -999, -999, -999],      # DEPRECATED\n",
        "    'use_pid': True,                            # DEPRECATED\n",
        "        \n",
        "    # Matlab\n",
        "    'matlab_path': r'C:/Users/pc/Desktop/Artificial Intellingence & Robotics/1y-2s/Intelligent and hybrid control/IHC_attidute_control/control_schemas',\n",
        "    'simulation_name': 'pid_reinforcement.slx', \n",
        "    'simulation_time': 40.0,    # Time of the simulation\n",
        "    'open_GUI': False,          # If True, it open the simulink schema\n",
        "\n",
        "    # Dataset\n",
        "    'max_len_dataset': 10000,\n",
        "\n",
        "    # Feed Forward Network \n",
        "    'input_dim': 4,               # Dimension of input layer\n",
        "    'output_dim': 1,              # Dimension of output layer\n",
        "    'hidden_dim': 10,             # Dimension of hidden layer\n",
        "    'standard_deviation': 0.1,\n",
        "    'output_range': 10,           # Max control value\n",
        "    'bias': False,                \n",
        "    'learning_rate': 0.001,       \n",
        "    'model_name': 'model.pt',     # Used to save weights\n",
        "    'model_path': 'weights/',     # Folder where save weights\n",
        "\n",
        "    # Train\n",
        "    'reward_control_factor': 0.02,  # facotr which damp the control. if 0 -> r=-e^2\n",
        "    'batch_size': 32,             # Batch size for training\n",
        "    'start_train_size': 1,        # DEPRECATED: Minium number of sample to traine\n",
        "    'n_episode': 1,                   \n",
        "    'frequency_update': 32,       # Frequency update of the network\n",
        "    'threshold_error': 30.0,    \n",
        "    'max_reward': -5, \n",
        "    'epsilon': 0.3,  \n",
        "    'max_abs_control': 5.0, \n",
        "\n",
        "    # Plots\n",
        "    'plots_path': 'plots/'        # Folder where save plots\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "class Color:\n",
        "    RED = '\\033[91m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    BLUE = '\\033[94m'\n",
        "    MAGENTA = '\\033[95m'\n",
        "    CYAN = '\\033[96m'\n",
        "    WHITE = '\\033[97m'\n",
        "    RESET = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actor-Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, lr, bias):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.loss_fnc = nn.MSELoss()\n",
        "        \n",
        "        self.layer_1 = nn.Linear(\n",
        "            in_features=self.input_dim,\n",
        "            out_features=self.hidden_dim,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "        \n",
        "        self.layer_2 = nn.Linear(\n",
        "            in_features=self.hidden_dim,\n",
        "            out_features=self.hidden_dim*2,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "        self.layer_3 = nn.Linear(\n",
        "            in_features=self.hidden_dim*2,\n",
        "            out_features=self.hidden_dim,\n",
        "            bias=bias\n",
        "        )\n",
        "        \n",
        "        self.layer_out= nn.Linear(\n",
        "            in_features=self.hidden_dim,\n",
        "            out_features=1,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "    def forward(self, state):\n",
        "\n",
        "        state = self.layer_1(state)\n",
        "        state = self.tanh(state)\n",
        "\n",
        "        state = self.layer_2(state)\n",
        "        state = self.tanh(state)\n",
        "\n",
        "        state = self.layer_3(state)\n",
        "        state = self.tanh(state)\n",
        "\n",
        "        state = self.layer_out(state)\n",
        "        \n",
        "        return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, lr, bias):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.loss_fnc = nn.MSELoss()\n",
        "        \n",
        "        \n",
        "        self.layer_1 = nn.Linear(\n",
        "            in_features=self.input_dim,\n",
        "            out_features=self.hidden_dim,\n",
        "            bias=bias\n",
        "        )\n",
        "        \n",
        "        \n",
        "        self.layer_2 = nn.Linear(\n",
        "            in_features=self.hidden_dim,\n",
        "            out_features=self.hidden_dim*2,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "        self.layer_3 = nn.Linear(\n",
        "            in_features=self.hidden_dim*2,\n",
        "            out_features=self.hidden_dim,\n",
        "            bias=bias\n",
        "        )\n",
        "        \n",
        "        self.layer_out = nn.Linear(\n",
        "            in_features=self.hidden_dim,\n",
        "            out_features=self.output_dim,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "    def forward(self, state):\n",
        "\n",
        "        state = self.layer_1(state)\n",
        "        state = self.tanh(state)\n",
        "        \n",
        "        state = self.layer_2(state)\n",
        "        state = self.tanh(state)\n",
        "\n",
        "        state = self.layer_3(state)\n",
        "        state = self.tanh(state)\n",
        "\n",
        "        state = self.layer_out(state)\n",
        "        mu = self.tanh(state)*global_var['max_abs_control']\n",
        "\n",
        "        return mu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, bias, std, lr, model_name):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.critic = Critic(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            bias=bias,\n",
        "            lr=lr\n",
        "            )\n",
        "\n",
        "        self.actor = Actor(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            output_dim=output_dim,\n",
        "            bias=bias,\n",
        "            lr=lr\n",
        "            )\n",
        "\n",
        "        self.log_std = nn.Parameter(torch.ones(1, output_dim) * std)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.loss_fnc = nn.MSELoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        value = self.critic(x)\n",
        "        mu    = self.actor(x)\n",
        "        std = self.log_std.exp().expand_as(mu)\n",
        "\n",
        "        action_distribution  = Normal(mu, std)\n",
        "        \n",
        "        action = action_distribution.sample()\n",
        "        raw_log_action = action_distribution.log_prob(action) # log probability of an action given the distribution\n",
        "\n",
        "        log_action = raw_log_action - torch.log( 1 - self.tanh(action)**2 + 1e-6  ) + torch.log( torch.tensor(global_var['max_abs_control']) )\n",
        "\n",
        "        # In statistic  given a random variable X, a transformation Y = f(X) is another random variable,\n",
        "        # the probability of Y is Py(Y) = Px( f(y)^-1 )*| D[f(y)^-1]_y |\n",
        "\n",
        "        # the transformation of log probability with tansh is the following:\n",
        "        # log( P ) = log( Pa ) - log( D[ tanh(a) ]_a ), where D[ tanh(a) ]_a = 1 - tanh(a)^2\n",
        "        # log( Pa ) is the probability density of a with the normal distribution\n",
        "\n",
        "        return action, value, action_distribution, log_action\n",
        "\n",
        "\n",
        "    def save(self):\n",
        "        name = self.model_name\n",
        "        torch.save(self.state_dict(), name )\n",
        "        #print(f\"{Color.MAGENTA}Saved: {name}{Color.RESET}\")\n",
        "\n",
        "    def load(self):\n",
        "        name = self.model_name\n",
        "        try:\n",
        "            self.load_state_dict(torch.load(name) )\n",
        "            print(f\"{Color.MAGENTA}loaded: {name}{Color.RESET}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{Color.RED}Model not loaded{Color.RESET}\")\n",
        "            print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_socket(ip_address, port_input):\n",
        "\n",
        "    #print(f\"{Color.YELLOW}ip: {ip_address}, port_input: {port_input}{Color.RESET}\")\n",
        "\n",
        "    try:\n",
        "        socket_nn_input = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        socket_nn_input.bind( (ip_address, port_input) )\n",
        "        socket_nn_input.listen(1)\n",
        "\n",
        "        #print(f\"{Color.BOLD}{Color.GREEN}Sockets listener created{Color.RESET}\")\n",
        "\n",
        "        return socket_nn_input\n",
        "    except Exception as e:\n",
        "        print(f\"{Color.RED}An error occurred: {e}{Color.RESET}\")\n",
        "\n",
        "        if 'socket_nn_input' in locals():\n",
        "            socket_nn_input.close()\n",
        "            \n",
        "        return None, None\n",
        "    \n",
        "def accept_connection(socket_server):\n",
        "    connection, address = socket_server.accept()\n",
        "    #print(f\"{Color.GREEN}Connection accepted!{Color.RESET}\")\n",
        "    return connection, address\n",
        "\n",
        "def receive_data(connection, buffer_size, dim_input):\n",
        "    \n",
        "    expected_bytes = buffer_size  # Size for one double\n",
        "    no_data_flag = False\n",
        "    data = b''\n",
        "    while len(data) < expected_bytes:\n",
        "        more_data = connection.recv(expected_bytes - len(data))\n",
        "\n",
        "        if not more_data:\n",
        "            print(\"\\nNo data received. Ending connection.\")\n",
        "            no_data_flag = True\n",
        "            break\n",
        "\n",
        "        data += more_data\n",
        "    data = list(struct.unpack(f'!{str(dim_input)}d', data))  # Unpack one double\n",
        "    \n",
        "    return data, no_data_flag\n",
        "\n",
        "def receive_data_excpt(connection, buffer_size, dim_input, stop_flag):\n",
        "    \n",
        "    expected_bytes = 8# buffer_size  # Size for one double\n",
        "    data = b''\n",
        "    #connection.settimeout(5.0)  # Set timeout to 5 seconds\n",
        "\n",
        "    try:\n",
        "        while len(data) < expected_bytes:\n",
        "            #more_data = connection.recv(expected_bytes - len(data))\n",
        "            more_data = connection.recv(expected_bytes)\n",
        "            if not more_data:\n",
        "                # No more data is available, break the loop\n",
        "                break\n",
        "            data += more_data\n",
        "        try:\n",
        "            #data = list(struct.unpack(f'!{str(dim_input)}d', data)) \n",
        "            data = list(struct.unpack(f'!d', data)) \n",
        "        except Exception as e:\n",
        "            print(f\"\\n{e}\")\n",
        "            print(f\"{Color.RED}\\nProblem with unpacking, error: {e}{Color.RESET}\")\n",
        "            print(f\"{Color.RED}May be due because return empty string when nothing is receive for a certain time{Color.RESET}\")\n",
        "            return stop_flag\n",
        "        \n",
        "    except Exception as e:\n",
        "\n",
        "        print(f\"\\n{e}\")\n",
        "        if isinstance(e, socket.timeout):\n",
        "            print(f\"{Color.RED}\\nTimeout error: No data received within the timeout period{Color.RESET}\")\n",
        "        else:\n",
        "            print(f\"{Color.RED}\\nOther exception occurred: {e}{Color.RESET}\")\n",
        "            print(f\"{Color.RED}Maybe due to some other error in the code{Color.RESET}\")\n",
        "            \n",
        "        print(f\"{Color.RED}May be due because return empty string when nothing is receive for a certain time{Color.RESET}\")\n",
        "        print(f\"{Color.BLUE}\\nNo data received within the timeout period, maybe some error of code{Color.RESET}\")\n",
        "       \n",
        "        return stop_flag\n",
        "    \n",
        "    connection.settimeout(None)\n",
        "    return data\n",
        "\n",
        "def send_data(connection, message, dim_output):\n",
        "    try:\n",
        "        #message_to_send = struct.pack(f'!{str(dim_output)}d', *message)  \n",
        "        message_to_send = struct.pack(f'!{str(dim_output)}d', message)\n",
        "        connection.sendall(message_to_send)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\rError sending float: {e}\", end='')\n",
        "\n",
        "def close_connections(*to_close):\n",
        "    try:\n",
        "        for c in to_close:\n",
        "            c.close()\n",
        "    except Exception as e:\n",
        "        print(f\"{Color.RED}\\nFailed to close connection: verified the follwing error:\\n{e}{Color.RESET}\")\n",
        "        return\n",
        "\n",
        "    #print(f\"{Color.GREEN}\\nSockets closed!{Color.RESET}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_simulink(model_name, matlab_path, simulation_time):\n",
        "\n",
        "    model_name = model_name.split('.')[0]\n",
        "\n",
        "    #print(f\"\\nStarting Matlab engine ... \", end='')\n",
        "    future = matlab.engine.start_matlab(background=True)\n",
        "    eng = future.result()  \n",
        "    #print(f\"Started!\")\n",
        "\n",
        "    eng.cd(matlab_path)\n",
        "    #print(\"MATLAB working directory:\", eng.pwd())\n",
        "\n",
        "    if global_var['open_GUI'] == False:\n",
        "        eng.load_system(model_name)\n",
        "    else:\n",
        "        eng.open_system(model_name, nargout=0)\n",
        "        \n",
        "    loaded_model = eng.bdroot()\n",
        "    #print(f\"The currently loaded model is: {loaded_model}\")\n",
        "\n",
        "    eng.set_param(model_name, 'StartTime', '0', nargout=0)\n",
        "    eng.set_param(model_name, 'StopTime', str(simulation_time), nargout=0)\n",
        "    eng.set_param(model_name, 'SimulationCommand', 'start', nargout=0)\n",
        "\n",
        "    return eng\n",
        "\n",
        "def run_simulink_with_gui(model_name, matlab_path, simulation_time):\n",
        "\n",
        "    model_name = model_name.split('.')[0]\n",
        "\n",
        "    #print(f\"\\nStarting Matlab engine ... \", end='')\n",
        "    future = matlab.engine.start_matlab(background=True)\n",
        "    eng = future.result()  \n",
        "    #print(f\"Started!\")\n",
        "\n",
        "    eng.cd(matlab_path)\n",
        "    #print(\"MATLAB working directory:\", eng.pwd())\n",
        "\n",
        "    eng.open_system(model_name, nargout=0)\n",
        "    loaded_model = eng.bdroot()\n",
        "\n",
        "    #print(f\"The currently loaded model is: {loaded_model}\")\n",
        "\n",
        "    eng.set_param(model_name, 'StartTime', '0', nargout=0)\n",
        "    eng.set_param(model_name, 'StopTime', str(simulation_time), nargout=0)\n",
        "    eng.set_param(model_name, 'SimulationCommand', 'start', nargout=0)\n",
        "\n",
        "    return eng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, states, rewards, actions, log_action, next_states):\n",
        "\n",
        "    # converting array of tensor inot a tensor of tensor to create the stack for the batch\n",
        "    \n",
        "    states = torch.stack( states, dim=0 )\n",
        "    rewards = torch.stack( rewards, dim=0)\n",
        "    actions = torch.stack( actions, dim=0)\n",
        "    log_action = torch.stack( log_action, dim=0)\n",
        "    next_states = torch.stack( next_states, dim=0)\n",
        "\n",
        "    #states = states.view( states.shape[0], -1)\n",
        "    #rewards = rewards.view( rewards.shape[0], -1)\n",
        "    #actions = actions.view( actions.shape[0] , -1)\n",
        "    #log_action = log_action.view( log_action.shape[0], -1)\n",
        "    #next_states = next_states.view( next_states.shape[0], -1)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss = 0\n",
        "    gamma = 0.99\n",
        "\n",
        "    model.critic.optimizer.zero_grad()\n",
        "    model.actor.optimizer.zero_grad()\n",
        "\n",
        "    ##### start calculating loss #####\n",
        "\n",
        "    #dist, values = model(states)\n",
        "    _, values, _, _ = model(states)\n",
        "\n",
        "    value_next_state = model.critic(next_states).detach()\n",
        "    label = rewards + gamma * value_next_state\n",
        "    delta =  label - values \n",
        "\n",
        "    critic_loss = model.critic.loss_fnc(delta, torch.zeros(delta.shape) ) \n",
        "    actor_loss = torch.mean(delta * log_action )\n",
        "    #actor_loss = actor_loss.mean()\n",
        "\n",
        "    #print(rewards.shape)\n",
        "    #print(values.shape)\n",
        "    #print(value_next_state.shape)\n",
        "    #print(delta)\n",
        "    #print(f\"Delta: {delta.mean():.3f}, actions: {actions.mean():.3f}, log_act: {log_action.mean():.3f}, Critic: {critic_loss:.3f}, Actor: {actor_loss:.3f}\")\n",
        "\n",
        "    ##### End calculating loss #####\n",
        "\n",
        "    actor_loss.backward(retain_graph=True)\n",
        "    critic_loss.backward()\n",
        "\n",
        "    model.critic.optimizer.step()\n",
        "    model.actor.optimizer.step()\n",
        "\n",
        "    model.save()\n",
        "    model.eval()\n",
        "\n",
        "    print()\n",
        "    print(\"*****\")\n",
        "    print(f\"val_state: {values.shape}, {values.mean()}\")\n",
        "    print(f\"val_next_state: {value_next_state.shape}, {value_next_state.mean()}\")\n",
        "    print(f\"label: {label.shape}, {label.mean()}\")\n",
        "    print(f\"delta: {delta.shape}, {delta.mean()} -> delta^2: {delta.mean()**2}\")\n",
        "    print(f\"log_action: {log_action.shape}, {log_action.mean()}\")\n",
        "    print(f\"Actor_loss: {actor_loss}\")\n",
        "    print(f\"Critic_loss: {critic_loss}\")\n",
        "\n",
        "    return actor_loss, critic_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_statistics(history_error, history_desired_input, history_reference_model, history_controlled_object, history_mean_error, history_reward, name):\n",
        "    time = np.linspace(0, int(global_var['simulation_time']), len(history_error))\n",
        "    time_reward = np.linspace(0, int(global_var['simulation_time']), len(history_reward))\n",
        "\n",
        "    fig, axs = plt.subplots(2,3,figsize=(18, 10))\n",
        "\n",
        "    axs[0, 0].plot(time, history_desired_input)\n",
        "    axs[0, 0].set_title('Desired input')\n",
        "    axs[0, 0].grid(True)\n",
        "\n",
        "    axs[0, 1].plot(time, history_reference_model)\n",
        "    axs[0, 1].set_title('Reference model')\n",
        "    axs[0, 1].grid(True)\n",
        "\n",
        "    axs[1, 0].plot(time, history_controlled_object)\n",
        "    axs[1, 0].set_title('Controlled object')\n",
        "    axs[1, 0].grid(True)\n",
        "\n",
        "    axs[1, 1].plot(time_reward, history_reward)\n",
        "    axs[1, 1].set_title('Reward')\n",
        "    axs[1, 1].grid(True)\n",
        "\n",
        "    axs[0, 2].plot(time, history_error)\n",
        "    axs[0, 2].set_title('Error')\n",
        "    axs[0, 2].grid(True)\n",
        "\n",
        "\n",
        "    axs[1, 2].plot(time, history_mean_error)\n",
        "    axs[1, 2].set_title('Abs mean error - last 50')\n",
        "    axs[1, 2].grid(True)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    fig_name = name + '_' + 'range_' + str(global_var['max_abs_control']) + '_sim_' + global_var['simulation_name'].split('.')[0] + '_' + str(int(global_var['simulation_time']))\n",
        "    print(fig_name)\n",
        "\n",
        "    plt.grid(True)\n",
        "    #plt.savefig(global_var['plots_path'] + fig_name)\n",
        "    plt.show(block=False)\n",
        "\n",
        "    \n",
        "    #plt.pause(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss(history_actor_loss, history_critic_loss, history_reward, history_error, name):\n",
        "    \n",
        "    clear_output(True)\n",
        "   \n",
        "    time = np.linspace(0, len(history_actor_loss) - 1, len(history_actor_loss))\n",
        "    time_reward = np.linspace(0, len(history_reward) - 1, len(history_reward))\n",
        "    time_error = np.linspace(0, len(history_error) - 1, len(history_error))\n",
        "\n",
        "    fig_1, axs_1 = plt.subplots(1,2,figsize=(12, 5))\n",
        "    fig_2, axs_2 = plt.subplots(1,2,figsize=(12, 5))\n",
        "\n",
        "\n",
        "    history_reward = torch.stack(history_reward).detach().cpu().numpy().flatten()\n",
        "    history_error = torch.stack(history_error).detach().cpu().numpy().flatten()\n",
        "\n",
        "    axs_1[0].plot(time, history_actor_loss)\n",
        "    axs_1[0].set_title('Actor loss')\n",
        "    axs_1[0].grid(True)\n",
        "\n",
        "    axs_1[1].plot(time, history_critic_loss)\n",
        "    axs_1[1].set_title('Critic loss')\n",
        "    axs_1[1].grid(True)\n",
        "\n",
        "    axs_2[0].plot(time_reward, history_reward)\n",
        "    axs_2[0].set_title('Reward')\n",
        "    axs_2[0].grid(True)\n",
        "\n",
        "    axs_2[1].plot(time_error, history_error)\n",
        "    axs_2[1].set_title('Error')\n",
        "    axs_2[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # fig_name = name + '_' + 'range_' + str(global_var['max_abs_control']) + '_sim_' + global_var['simulation_name'].split('.')[0] + '_' + str(int(global_var['simulation_time']))\n",
        "    # print(fig_name)\n",
        "\n",
        "    plt.grid(True)\n",
        "    #plt.savefig(global_var['plots_path'] + fig_name)\n",
        "    plt.show(block=False)\n",
        "\n",
        "    #display(plt.gcf())  # Display the current figure\n",
        "    #clear_output(wait=True)  # Clear the output before the next plot\n",
        "    #plt.close(fig)\n",
        "\n",
        "    \n",
        "    \n",
        "    #plt.pause(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_reward(error, control):\n",
        "\n",
        "    error = error #/ global_var['threshold_error']\n",
        "    control = control#/ global_var['max_abs_control']\n",
        "\n",
        "    reward = abs(error) + abs(global_var['reward_control_factor']*(control.item()) )\n",
        "    reward = -reward\n",
        "\n",
        "    reward = max(reward, -abs(global_var['max_reward']) )\n",
        "    \n",
        "    reward = torch.tensor([reward], dtype=torch.float, requires_grad=True)\n",
        "\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def play_episode( connection_receiver, \n",
        "                  connection_sender, \n",
        "                  network, \n",
        "                  history_desired_input, \n",
        "                  history_reference_model,\n",
        "                  history_controlled_object,\n",
        "                  history_error,\n",
        "                  history_mean_error,\n",
        "                  history_reward,\n",
        "                  mean_error_window,\n",
        "                  train_flag\n",
        "                  ):\n",
        "    \n",
        "    n_received = 0\n",
        "    n_sent = 0\n",
        "    n_train = 0\n",
        "    mean_loss = 0\n",
        "    n_random = 0\n",
        "    actor_loss = 0.0\n",
        "    critic_loss = 0.0\n",
        "    penalize_flag = False\n",
        "    \n",
        "    states_array = []\n",
        "    actions_array = []\n",
        "    log_prob_array = []\n",
        "    rewards_array = []\n",
        "    error_array = []\n",
        "    next_states_array = []\n",
        "\n",
        "    loss_array = []\n",
        "    actor_loss_array = []\n",
        "    critic_loss_array = []\n",
        "\n",
        "    while True:\n",
        "\n",
        "        raw_data, _ = receive_data(\n",
        "            connection=connection_receiver, \n",
        "            buffer_size=global_var['buffer_size'],\n",
        "            dim_input=global_var['connection_dim_input']\n",
        "            )\n",
        "        n_received += 1\n",
        "        \n",
        "       \n",
        "        history_controlled_object.append(raw_data[0])\n",
        "        history_desired_input.append(raw_data[1])\n",
        "        history_reference_model.append(raw_data[2])\n",
        "        history_error.append(raw_data[-1])\n",
        "        history_mean_error.append(abs(np.mean(history_error[-mean_error_window:])))\n",
        "        \n",
        "    \n",
        "        if abs(raw_data[-1]) > global_var['threshold_error'] and n_received > 1: # end episode if diverging\n",
        "            penalize_flag = True\n",
        "        \n",
        "        raw_data = torch.tensor(raw_data, requires_grad=False)\n",
        "\n",
        "        if len(next_states_array) > 1 and ( len(next_states_array) % global_var['frequency_update'] ) == 0 and train_flag == True:\n",
        "            \n",
        "            current_loss = 0\n",
        "            mean_loss = 0\n",
        "            \n",
        "            actor_loss, critic_loss = train(\n",
        "                model=network,\n",
        "                states=states_array[-global_var['frequency_update']:],\n",
        "                actions=actions_array[-global_var['frequency_update']:],\n",
        "                log_action=log_prob_array[-global_var['frequency_update']:],\n",
        "                rewards=rewards_array[-global_var['frequency_update']:],\n",
        "                next_states=next_states_array[-global_var['frequency_update']:]\n",
        "            )  \n",
        "            n_train += 1\n",
        "            \n",
        "            #mean_loss = torch.mean( torch.stack(actor_loss + critic_loss, dim=0))\n",
        "\n",
        "            actor_loss = actor_loss.item()\n",
        "            critic_loss = critic_loss.item()\n",
        "            \n",
        "            actor_loss_array.append(actor_loss)\n",
        "            critic_loss_array.append(critic_loss)\n",
        "            loss_array.append(actor_loss + critic_loss)\n",
        "            \n",
        "            '''\n",
        "            if ( n_train % 10 ) == 0 or penalize_flag == True:\n",
        "                plot_loss(\n",
        "                    history_actor_loss=actor_loss_array,\n",
        "                    history_critic_loss=critic_loss_array,\n",
        "                    history_reward=rewards_array,\n",
        "                    history_error=error_array,\n",
        "                    name='Loss'\n",
        "                )\n",
        "            '''\n",
        "\n",
        "            if penalize_flag == True : # end episode if diverging\n",
        "                penalize_flag = False\n",
        "                print(f\"{Color.RED}\\n---- Error too high, Restarting episode{Color.RESET}\")\n",
        "                raise Exception(\"Error too high, Restarting episode\")\n",
        "            \n",
        "            \n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            network_input = raw_data.unsqueeze(0)\n",
        "            action, value, action_distribution, log_action = network(network_input)\n",
        "\n",
        "            action = action.squeeze(0)\n",
        "            value = value.squeeze(0)\n",
        "            log_action = log_action.squeeze(0)\n",
        "\n",
        "        \n",
        "        if random.random() < global_var['epsilon'] and train_flag == True:\n",
        "            action = torch.rand( action.shape )\n",
        "            action = torch.clip(action, min=-global_var['max_abs_control'], max=global_var['max_abs_control'])\n",
        "            action = action\n",
        "            n_random += 1\n",
        "        else:\n",
        "            action = action\n",
        "            \n",
        "        current_reward = compute_reward( raw_data[-1], action )\n",
        "\n",
        "\n",
        "        raw_data.requires_grad_(True)\n",
        "        action.requires_grad_(True)\n",
        "        current_reward.requires_grad_(True)\n",
        "\n",
        "        if penalize_flag == True:\n",
        "            #current_reward = current_reward\n",
        "            current_reward = torch.tensor([ -abs(global_var['max_reward'])*2.0], dtype=torch.float, requires_grad=True)\n",
        "\n",
        "        history_reward.append(current_reward.item())\n",
        "            \n",
        "        states_array.append( raw_data )\n",
        "        log_prob_array.append(log_action)\n",
        "        rewards_array.append( current_reward )\n",
        "        error_array.append( raw_data[-1] )\n",
        "        \n",
        "        \n",
        "\n",
        "        if not ( states_array == []):\n",
        "            current_next_state = states_array[-1].clone()\n",
        "            current_next_state.requires_grad_(True)\n",
        "            next_states_array.append( current_next_state )\n",
        "        \n",
        "        \n",
        "        \n",
        "        actions_array.append( action )\n",
        "\n",
        "        \n",
        "        #print(f\"raw_data: {raw_data}, shape: {raw_data.shape}\")\n",
        "        #print(f\"log_action: {log_action}, shape: {log_action.shape}\")\n",
        "        #print(f\"current_reward: {current_reward}, shape: {current_reward.shape}\")\n",
        "        #print(f\"action: {action}, shape: {action.shape}\")\n",
        " \n",
        "    \n",
        "        send_data(\n",
        "            connection=connection_sender, \n",
        "            message=action.item(), \n",
        "            dim_output=global_var['connection_dim_output']\n",
        "            )\n",
        "        n_sent += 1\n",
        "\n",
        "        output_line = (\n",
        "            f\"\\rreceived: {n_received}, sent: {n_sent}, n_train: {n_train}, \"\n",
        "            f\"error: {raw_data[-1]:.4f}, reward : {current_reward.item():.4f}\" #, actor_loss: {np.mean(actor_loss_array[-mean_error_window:]) }, critic_loss: {np.mean(critic_loss_array[-mean_error_window:])}\"\n",
        "            f\" mean_error_{str(mean_error_window)}: {np.mean(history_error[-mean_error_window:]):.4f} ,mean loss: {mean_loss:.4f}{' ' * 50}\"\n",
        "        )\n",
        "        \n",
        "        #print(output_line, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialization_connection_and_simulink( ip_address, \n",
        "                                            port_input, \n",
        "                                            port_output,\n",
        "                                            simulation_name,\n",
        "                                            simulation_time,\n",
        "                                            matlab_path\n",
        "                                            ):\n",
        "    receiver_socket = setup_socket(\n",
        "        ip_address=ip_address, \n",
        "        port_input=port_input\n",
        "        )\n",
        "\n",
        "    send_socket = setup_socket(\n",
        "        ip_address=ip_address, \n",
        "        port_input=port_output\n",
        "        )\n",
        "        \n",
        "\n",
        "    #eng = run_simulink_with_gui(model_name, eng_path, simulation_time)\n",
        "    \n",
        "    eng = run_simulink(\n",
        "        model_name=simulation_name, \n",
        "        matlab_path=matlab_path, \n",
        "        simulation_time=simulation_time\n",
        "        )\n",
        "\n",
        "\n",
        "    #print(f\"{Color.CYAN}\\nWaiting someone to connect ...{Color.RESET}\")\n",
        "    connection_receiver, addr = accept_connection(receiver_socket)\n",
        "    connection_sender, addr = accept_connection(send_socket)\n",
        "\n",
        "    return receiver_socket, send_socket, connection_receiver, connection_sender, eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reinforcement_training_loop(\n",
        "        network,\n",
        "        history_desired_input,\n",
        "        history_reference_model,\n",
        "        history_controlled_object,\n",
        "        history_error,\n",
        "        history_mean_error,\n",
        "        mean_error_window,\n",
        "        history_reward, \n",
        "):    \n",
        "    try:\n",
        "\n",
        "        receiver_socket, send_socket, connection_receiver, connection_sender, eng = initialization_connection_and_simulink(\n",
        "                                                                                                                        ip_address=global_var['ip_address'],\n",
        "                                                                                                                        port_input=global_var['port_input'],\n",
        "                                                                                                                        port_output=global_var['port_output'],\n",
        "                                                                                                                        simulation_name=global_var['simulation_name'],\n",
        "                                                                                                                        simulation_time=global_var['simulation_time'],\n",
        "                                                                                                                        matlab_path=global_var['matlab_path']\n",
        "                                                                                                                    )\n",
        "        play_episode_v2(\n",
        "            connection_receiver=connection_receiver, \n",
        "            connection_sender=connection_sender, \n",
        "            network=network, \n",
        "            history_desired_input=history_desired_input, \n",
        "            history_reference_model=history_reference_model,\n",
        "            history_controlled_object=history_controlled_object,\n",
        "            history_error=history_error,\n",
        "            history_mean_error=history_mean_error,\n",
        "            history_reward=history_reward,\n",
        "            mean_error_window=mean_error_window,\n",
        "            train_flag = True\n",
        "            )\n",
        "       \n",
        "        \n",
        "    except Exception as e:\n",
        "        print()\n",
        "        print(e)\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "\n",
        "        close_connections(\n",
        "            connection_receiver,\n",
        "            connection_sender,\n",
        "            send_socket,\n",
        "            receiver_socket,\n",
        "        )\n",
        "\n",
        "        eng.quit()\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def play_reinforcement_loop(\n",
        "        network,\n",
        "        history_desired_input,\n",
        "        history_reference_model,\n",
        "        history_controlled_object,\n",
        "        history_error,\n",
        "        history_mean_error,\n",
        "        history_reward,\n",
        "        mean_error_window,\n",
        "): \n",
        "    for e in range(global_var['n_episode']):\n",
        "        print(f\"\\rn_episode: {e}\\n\", end=\"\")\n",
        "\n",
        "        history_desired_input = []\n",
        "        history_reference_model = []\n",
        "        history_controlled_object = []\n",
        "        history_error = []\n",
        "        history_mean_error = []\n",
        "        history_reward = []\n",
        "\n",
        "        reinforcement_training_loop(\n",
        "                network=network,\n",
        "                history_desired_input=history_desired_input,\n",
        "                history_reference_model=history_reference_model,\n",
        "                history_controlled_object=history_controlled_object,\n",
        "                history_error=history_error,\n",
        "                history_mean_error=history_mean_error,\n",
        "                history_reward=history_reward,\n",
        "                mean_error_window=mean_error_window,\n",
        "        )\n",
        "\n",
        "        if (e % 50) == 0:\n",
        "            network.save()     \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PPO Algorithm "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ppo_train(model, state_memory, action_memory, reward_memory, log_prog_memory, state_value_memory, next_state_memory):\n",
        "\n",
        "\n",
        "    state_memory = torch.stack(state_memory, dim=0)\n",
        "    action_memory = torch.stack(action_memory, dim=0)\n",
        "    reward_memory = torch.stack(reward_memory, dim=0)\n",
        "    log_prog_memory = torch.stack(log_prog_memory, dim=0)\n",
        "    state_value_memory = torch.stack(state_value_memory, dim=0)\n",
        "    next_state_memory = torch.stack(next_state_memory, dim=0)\n",
        "\n",
        "    model.critic.optimizer.zero_grad()\n",
        "    model.actor.optimizer.zero_grad()\n",
        "\n",
        "    ### calculating loss\n",
        "    delta = reward_memory + 0.99*next_state_memory - state_memory\n",
        "    \n",
        "    critic_loss = model.critic.loss_fnc(delta, torch.zeros(delta.shape) )\n",
        "    actor_loss = -(log_prog_memory * delta.detach()).mean()\n",
        "\n",
        "    ### optimizing\n",
        "    actor_loss.backward(retain_graph=True)\n",
        "    critic_loss.backward()\n",
        "\n",
        "    model.critic.optimizer.step()\n",
        "    model.actor.optimizer.step()\n",
        "\n",
        "    model.save()\n",
        "    model.eval()\n",
        "\n",
        "    return actor_loss, critic_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def play_episode_v2( \n",
        "                    connection_receiver, \n",
        "                    connection_sender, \n",
        "                    network,\n",
        "                    history_desired_input, \n",
        "                    history_reference_model,\n",
        "                    history_controlled_object,\n",
        "                    history_error,\n",
        "                    history_mean_error,\n",
        "                    history_reward,\n",
        "                    mean_error_window,\n",
        "                    train_flag = True\n",
        "                  ):\n",
        "    \n",
        "    done = False\n",
        "    state_memory = []\n",
        "    action_memory = []\n",
        "    reward_memory = []\n",
        "    log_prob_memory = []\n",
        "    state_value_memory = []\n",
        "    next_state_memory = []\n",
        "\n",
        "    history_actor_loss = []\n",
        "    history_critic_loss = []\n",
        "    history_error = []\n",
        "    history_reward = []\n",
        "\n",
        "    ### Receiving first state\n",
        "    raw_state, _ = receive_data(\n",
        "        connection=connection_receiver, \n",
        "        buffer_size=global_var['buffer_size'],\n",
        "        dim_input=global_var['connection_dim_input']\n",
        "        )\n",
        "        \n",
        "\n",
        "    state = torch.tensor( raw_state, dtype=torch.float32)\n",
        "\n",
        "    while done == False:\n",
        "\n",
        "        for _ in range( global_var['batch_size'] ):\n",
        "\n",
        "            #state = torch.tensor( state, dtype=torch.float32)\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            ### Calculating value for this state\n",
        "            action, state_value, action_distribution, log_prob = network(state)\n",
        "\n",
        "\n",
        "            ### Going to the next state\n",
        "            send_data(\n",
        "                connection=connection_sender, \n",
        "                message=action.item(), \n",
        "                dim_output=global_var['connection_dim_output']\n",
        "            )\n",
        "\n",
        "            next_raw_data, _ = receive_data(\n",
        "                connection=connection_receiver, \n",
        "                buffer_size=global_var['buffer_size'],\n",
        "                dim_input=global_var['connection_dim_input']\n",
        "                )\n",
        "            \n",
        "            next_state = torch.tensor(next_raw_data, dtype=torch.float32)\n",
        "\n",
        "            ### check condition of termination\n",
        "            if abs(next_state[-1]) > global_var['threshold_error']:\n",
        "                done = True\n",
        "\n",
        "            ### Computing rewward\n",
        "            reward = compute_reward( next_state[-1], action)\n",
        "\n",
        "            history_error.append( next_state.item()[-1] )\n",
        "            history_reward.append(reward.item())\n",
        "\n",
        "\n",
        "            ### adjusting dimension and appending\n",
        "            state = state.squeeze(0)\n",
        "            action = action.squeeze(0)\n",
        "            log_prob = log_prob.squeeze(0)\n",
        "            state_value = state_value.squeeze(0)\n",
        "\n",
        "            state_memory.append(state)\n",
        "            action_memory.append(action)\n",
        "            reward_memory.append(reward)\n",
        "            log_prob_memory.append(log_prob)\n",
        "            state_value_memory.append(state_value)\n",
        "            next_state_memory.append(next_state)\n",
        "\n",
        "            ### Iterating\n",
        "            state = next_state.clone().detach() \n",
        "\n",
        "        ### Update of network\n",
        "        actor_loss, critic_loss = ppo_train(\n",
        "                                            model=network,\n",
        "                                            state_memory=state_memory,\n",
        "                                            action_memory=action_memory,\n",
        "                                            reward_memory=reward_memory,\n",
        "                                            log_prog_memory=log_prob_memory,\n",
        "                                            state_value_memory=state_value_memory,\n",
        "                                            next_state_memory=next_state_memory\n",
        "                                        )\n",
        "\n",
        "        history_actor_loss.append( actor_loss.item() )\n",
        "        history_critic_loss.append( critic_loss.item() ) \n",
        "\n",
        "        ### Clear memory\n",
        "        state_memory = []\n",
        "        action_memory = []\n",
        "        reward_memory = []\n",
        "        log_prob_memory = []\n",
        "        state_value_memory = []\n",
        "        next_state_memory = []\n",
        "\n",
        "    if done == True : \n",
        "        print(f\"{Color.RED}\\n---- Error too high, Restarting episode{Color.RESET}\")\n",
        "        raise Exception(\"Error too high, Restarting episode\")\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ActorCritic(\n",
              "  (critic): Critic(\n",
              "    (relu): ReLU()\n",
              "    (tanh): Tanh()\n",
              "    (loss_fnc): MSELoss()\n",
              "    (layer_1): Linear(in_features=4, out_features=10, bias=False)\n",
              "    (layer_2): Linear(in_features=10, out_features=20, bias=False)\n",
              "    (layer_3): Linear(in_features=20, out_features=10, bias=False)\n",
              "    (layer_out): Linear(in_features=10, out_features=1, bias=False)\n",
              "  )\n",
              "  (actor): Actor(\n",
              "    (relu): ReLU()\n",
              "    (tanh): Tanh()\n",
              "    (loss_fnc): MSELoss()\n",
              "    (layer_1): Linear(in_features=4, out_features=10, bias=False)\n",
              "    (layer_2): Linear(in_features=10, out_features=20, bias=False)\n",
              "    (layer_3): Linear(in_features=20, out_features=10, bias=False)\n",
              "    (layer_out): Linear(in_features=10, out_features=1, bias=False)\n",
              "  )\n",
              "  (tanh): Tanh()\n",
              "  (loss_fnc): MSELoss()\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "network = ActorCritic(  \n",
        "                        input_dim=global_var['input_dim'],\n",
        "                        output_dim=global_var['output_dim'],\n",
        "                        hidden_dim=global_var['hidden_dim'],\n",
        "                        bias=global_var['bias'],\n",
        "                        #output_range=global_var['output_range'],\n",
        "                        std=global_var['standard_deviation'],\n",
        "                        lr=global_var['learning_rate'],\n",
        "                        model_name=global_var['model_path']+global_var['model_name']\n",
        "                    )\n",
        "\n",
        "network.eval()\n",
        "#network.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://simple-pid.readthedocs.io/en/latest/reference.html\n",
        "\n",
        "n_received = 0\n",
        "n_sent = 0\n",
        "previous_error = 0\n",
        "\n",
        "history_desired_input = []\n",
        "history_reference_model = []\n",
        "history_controlled_object = []\n",
        "history_error = []\n",
        "history_mean_error = []\n",
        "history_reward = []\n",
        "\n",
        "mean_error_window = 50\n",
        "mean_loss = 0\n",
        "n_train = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_episode: 0\n",
            "\n",
            "a Tensor with 4 elements cannot be converted to Scalar\n"
          ]
        }
      ],
      "source": [
        "play_reinforcement_loop(\n",
        "        network=network,\n",
        "        history_desired_input=history_desired_input,\n",
        "        history_reference_model=history_reference_model,\n",
        "        history_controlled_object=history_controlled_object,\n",
        "        history_error=history_error,\n",
        "        history_mean_error=history_mean_error,\n",
        "        history_reward=history_reward,\n",
        "        mean_error_window=mean_error_window,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "network.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_range_5.0_sim_pid_reinforcement_40\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x1000 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_statistics(\n",
        "    history_error=history_error,\n",
        "    history_desired_input=history_desired_input,\n",
        "    history_reference_model=history_reference_model,\n",
        "    history_controlled_object=history_controlled_object,\n",
        "    history_mean_error=history_mean_error,\n",
        "    history_reward=history_reward, \n",
        "    name='train'\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zSHiaIsp_hxu",
        "Fy_Ly0wC_Yiv",
        "n6oG4o52CyUV",
        "7u6gHkN0qTzc"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
